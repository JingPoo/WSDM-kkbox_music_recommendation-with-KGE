{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from KGE.data_utils import index_kg, convert_kg_to_index\n",
    "from KGE.models.translating_based.TransE import TransE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=', 'has_interest',\n",
       "        'BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik='],\n",
       "       ['Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=', 'has_interest',\n",
       "        'bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM='],\n",
       "       ['Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=', 'has_interest',\n",
       "        'JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY='],\n",
       "       ...,\n",
       "       ['ZxbVmt3Kh/XOH+h58c2Kdj6SjFZk+wnUO006IgWzMQE=', 'has_interest',\n",
       "        '750RprmFfLV0bymtDH88g24pLZGVi5VpBAI300P6UOA='],\n",
       "       ['0aH4Hd3ziPSRHClRX8rkeOEaAG5EPPkW1mKGCdXEok0=', 'has_interest',\n",
       "        'G8wgqObgeAMER/rVCIlgcNeQ8mm0CzF/GsxiMK8TTnA='],\n",
       "       ['0aH4Hd3ziPSRHClRX8rkeOEaAG5EPPkW1mKGCdXEok0=', 'has_interest',\n",
       "        'Ju0VGkjWeBUZCd7r5Az2hUImhMoWxWLUicOedsmvG0g=']], dtype='<U44')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "interest_data = pd.read_csv('./data/KKBOX/kgdata_interest.csv').to_numpy()\n",
    "interest_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kg_train_val_test_split(data, test_size, val_size):\n",
    "    '''\n",
    "        Parameters\n",
    "        ----------\n",
    "            data: the data to be split\n",
    "            test_size: if float, represent the proportion of the dataset to include in the test split\n",
    "                    if int, represents the absolute number of test samples\n",
    "            val_size: same as test_size, but is the proportion of the train data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            train, valid, test\n",
    "    '''\n",
    "   \n",
    "    # sort by first column\n",
    "    sorted_data = data[np.argsort(data[:,0])]\n",
    "\n",
    "    # get unique user index and count\n",
    "    unique_head, index, count = np.unique(sorted_data[:,0], return_index=True, return_counts=True)\n",
    "\n",
    "    # train test split\n",
    "    train_origin = [] \n",
    "    test = []\n",
    "    \n",
    "    for i in range(len(index)):\n",
    "        if count[i]>1:\n",
    "            tr, te = train_test_split(sorted_data[index[i]:index[i] + count[i], :], test_size=test_size, random_state=i)\n",
    "            train_origin.append(tr)\n",
    "            test.append(te)\n",
    "        else: #只有一筆\n",
    "            test.append(sorted_data[index[i],:])\n",
    "            \n",
    "    # train val split\n",
    "    valid = []\n",
    "    train = []\n",
    "\n",
    "    for j in range(len(train_origin)):\n",
    "        if len(train_origin[j])>1:\n",
    "            tr, va = train_test_split(train_origin[j], test_size=val_size, random_state=j)\n",
    "            train.append(tr)\n",
    "            valid.append(va)\n",
    "        else: #只有一筆\n",
    "            valid.append(train_origin[j])\n",
    "    \n",
    "    \n",
    "    return np.vstack(train), np.vstack(valid), np.vstack(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = kg_train_val_test_split(interest_data, 0.33, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read other data\n",
    "other_data = pd.read_csv('./data/KKBOX/kgdata_other.csv').to_numpy()\n",
    "other_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate kgdata_interest & kgdata_other as train\n",
    "train = np.concatenate((train, other_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data before index\n",
    "pd.DataFrame(train,columns=['h','r','t']).to_csv('./data/KKBOX/train_data.csv', index=False)\n",
    "pd.DataFrame(valid,columns=['h','r','t']).to_csv('./data/KKBOX/valid_data.csv', index=False)\n",
    "pd.DataFrame(test,columns=['h','r','t']).to_csv('./data/KKBOX/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the kg data (編號entity and relation)\n",
    "metadata = index_kg(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output metadata json\n",
    "\n",
    "with open('./data/KKBOX/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver kg into index\n",
    "train = convert_kg_to_index(train, metadata[\"ent2ind\"], metadata[\"rel2ind\"])\n",
    "valid = convert_kg_to_index(valid, metadata[\"ent2ind\"], metadata[\"rel2ind\"])\n",
    "test = convert_kg_to_index(test, metadata[\"ent2ind\"], metadata[\"rel2ind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data after index\n",
    "pd.DataFrame(train,columns=['h','r','t']).to_csv('./data/KKBOX/train_index_data.csv', index=False)\n",
    "pd.DataFrame(valid,columns=['h','r','t']).to_csv('./data/KKBOX/valid_index_data.csv', index=False)\n",
    "pd.DataFrame(test,columns=['h','r','t']).to_csv('./data/KKBOX/test_index_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41df773a823dbf9f934078d72fc2940838300d32d879c38d557790ddf6e50e9d"
  },
  "kernelspec": {
   "display_name": "Python 3.5.5 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
